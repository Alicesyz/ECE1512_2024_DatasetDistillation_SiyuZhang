# -*- coding: utf-8 -*-
"""TASK1_TRAIN_ORIGINAL_MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TsbJ81rFvPGySLa7Tr6obwjMas53ppJt
"""

!pip install ptflops
!pip install torchprofile

import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from networks import ConvNet
import time
import torch.nn as nn
from ptflops import get_model_complexity_info

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

transform = transforms.Compose([transforms.ToTensor()])
mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)

# Load the MNIST Test Dataset
mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
test_loader = DataLoader(mnist_test, batch_size=256, shuffle=False)

# Function to calculate FLOPs
def calculate_flops(model, input_res=(1, 28, 28)):
    flops, params = get_model_complexity_info(model, input_res, as_strings=True, print_per_layer_stat=False)
    #print(f"FLOPs: {flops}, Params: {params}")
    return flops, params

# Train the Model on the Original MNIST Training Dataset
def train_on_mnist_data(train_loader, num_epochs=20, lr=0.01):
    model = ConvNet(channel=1, num_classes=10, net_width=128, net_depth=3, net_act='relu',
                    net_norm='batchnorm', net_pooling='avgpooling', im_size=(28, 28)).to(device)

    # Calculate FLOPs
    calculate_flops(model, input_res=(1, 28, 28))

    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)
    criterion = nn.CrossEntropyLoss()

    model.train()
    start_time = time.time()  # Start training time
    for epoch in range(num_epochs):
        epoch_loss = 0
        correct = 0
        total = 0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()

            # Calculate training accuracy
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        # Calculate average loss and accuracy for the epoch
        epoch_accuracy = 100 * correct / total
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}, Accuracy: {epoch_accuracy:.2f}%")

    end_time = time.time()  # End training time
    training_time = end_time - start_time
    print(f"Total Training Time: {training_time:.2f} seconds")

    return model, training_time


# Evaluate the Model on the Real MNIST Test Set with Timing
def evaluate_on_test_set(model, test_loader):
    model.eval()
    correct = 0
    total = 0
    start_time = time.time()  # Start testing time
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    end_time = time.time()  # End testing time
    testing_time = end_time - start_time
    accuracy = correct / total
    print(f"Test Accuracy on Real MNIST Test Set: {accuracy:.4f}")
    print(f"Total Testing Time: {testing_time:.2f} seconds")
    return accuracy, testing_time

# Train the model on original MNIST data
model, training_time = train_on_mnist_data(train_loader)
# Evaluate the model
test_accuracy, testing_time = evaluate_on_test_set(model, test_loader)

from ptflops import get_model_complexity_info

#calculate flops
flops, params = get_model_complexity_info(model, (1, 28, 28), as_strings=False, print_per_layer_stat=False)
print(f"FLOPs: {flops:.2e}")

"""/// show 10 images by random select"""

import matplotlib.pyplot as plt

# Load the Original MNIST Dataset
transform = transforms.Compose([transforms.ToTensor()])
mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)

def display_mnist_images(dataset, num_images):
    plt.figure(figsize=(10, 2))
    for i in range(num_images):
        index = torch.randint(0, len(dataset), size=(1,)).item()
        image, label = dataset[index]
        image = image.squeeze(0)
        plt.subplot(1, num_images, i + 1)
        plt.imshow(image, cmap="gray")
        plt.title(f"Label: {label}")
        plt.axis("off")
    plt.show()

display_mnist_images(mnist_train, num_images=10)