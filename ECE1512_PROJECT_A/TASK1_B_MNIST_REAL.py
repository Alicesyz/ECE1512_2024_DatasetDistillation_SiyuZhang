# -*- coding: utf-8 -*-
"""TASK1_B_MNIST_REAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xnYbf4Bnp0fBsa_16ZfL-5f2x_3luGFQ
"""

import matplotlib.pyplot as plt
import torch
import torch.optim as optim
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import random
from networks import ConvNet  # Assuming ConvNet from networks.py

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define the attention matching function with synthetic data initialized from real images
def run_attention_matching_mnist(
    num_weight_initializations=100,
    model_update_steps=50,           # Number of optimization steps for the model
    lr_synthetic=0.1,
    synthetic_update_steps=1,
    lr_model=0.01,
    task_balance_lambda=0.01,
    num_epochs=20,
    images_per_class=10,
    minibatch_size=256
):
    # Set up MNIST data loader
    transform = transforms.Compose([transforms.ToTensor()])
    mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
    mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

    train_loader = DataLoader(mnist_train, batch_size=minibatch_size, shuffle=True)
    test_loader = DataLoader(mnist_test, batch_size=minibatch_size, shuffle=False)

    # Initialize synthetic data by randomly selecting real images from the MNIST dataset
    num_classes = 10
    synthetic_data = []

    # Group MNIST training images by class for easier selection
    mnist_images_by_class = {i: [] for i in range(num_classes)}
    for image, label in mnist_train:
        mnist_images_by_class[label].append(image)

    # Randomly select images_per_class real images for each class
    for class_idx in range(num_classes):
        selected_images = random.sample(mnist_images_by_class[class_idx], images_per_class)
        class_tensor = torch.stack([img for img in selected_images]).to(device).requires_grad_(True)
        synthetic_data.append(class_tensor)

    # Generate labels for the synthetic dataset
    synthetic_labels = torch.tensor([i for i in range(num_classes) for _ in range(images_per_class)], device=device)

    # Start Attention Matching process
    for epoch in range(num_epochs):
        print(f"Epoch {epoch+1}/{num_epochs}")
        epoch_loss = 0  # Track loss for each epoch

        for weight_init_iter in range(num_weight_initializations):
            # Initialize the ConvNet model for each reinitialization
            model = ConvNet(
                channel=1, num_classes=10, net_width=128, net_depth=3,
                net_act='relu', net_norm='batchnorm', net_pooling='avgpooling', im_size=(28, 28)
            ).to(device)

            model_optimizer = optim.SGD(model.parameters(), lr=lr_model, momentum=0.9)

            # Model training on synthetic data for `model_update_steps` iterations
            for update_step in range(model_update_steps):
                synthetic_inputs = torch.cat([sd.clone().detach().requires_grad_(True) for sd in synthetic_data]).to(device)

                model_output = model(synthetic_inputs)
                model_loss = nn.CrossEntropyLoss()(model_output, synthetic_labels)

                model_optimizer.zero_grad()
                model_loss.backward()
                model_optimizer.step()
                epoch_loss += model_loss.item()

            # Update synthetic data with attention matching
            for synthetic_step in range(synthetic_update_steps):
                for class_idx, synthetic_class_data in enumerate(synthetic_data):
                    synthetic_class_data = synthetic_class_data.clone().detach().requires_grad_(True)
                    synthetic_optimizer = optim.SGD([synthetic_class_data], lr=lr_synthetic)

                    real_images, real_labels = next(iter(train_loader))
                    real_images, real_labels = real_images.to(device), real_labels.to(device)

                    model.eval()
                    synthetic_output = model(synthetic_class_data)
                    real_output = model(real_images)

                    attention_loss = task_balance_lambda * ((synthetic_output - real_output[:images_per_class].detach()) ** 2).mean()

                    synthetic_optimizer.zero_grad()
                    attention_loss.backward()
                    synthetic_optimizer.step()

                    synthetic_data[class_idx] = synthetic_class_data.detach().requires_grad_(True)

        print(f"Epoch {epoch+1} Completed - Average Loss: {epoch_loss / (num_weight_initializations * model_update_steps):.4f}")

    # Visualize the condensed synthetic images
    save_synthetic_images(synthetic_data)

    # Evaluate the model on the test set
    evaluate_model(model, test_loader)

import os
from torchvision.utils import save_image

def save_synthetic_images(synthetic_data, save_dir="synthetic_images"):
    os.makedirs(save_dir, exist_ok=True)  # Create directory to save images

    num_classes = len(synthetic_data)
    images_per_class = synthetic_data[0].shape[0]  # Number of images per class

    for class_idx, class_data in enumerate(synthetic_data):
        for img_idx in range(images_per_class):
            # Extract each image, resize to 28x28 if necessary, and save it
            image = class_data[img_idx].detach().cpu()

            # Save each image with a specific filename
            filename = f"{save_dir}/class_{class_idx}_image_{img_idx + 1}.png"
            save_image(image, filename)
            #print(f"Saved {filename}")

def evaluate_model(model, test_loader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    test_accuracy = correct / total
    print(f"Test Accuracy: {test_accuracy:.4f}")

run_attention_matching_mnist()